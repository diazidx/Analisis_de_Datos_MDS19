{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso Análisis y limpieza de datos\n",
    "\n",
    "**Profesor responsable:** Jorge Alexis Castillo Sepúlveda, PhD, MSc & Math. Eng.\n",
    "\n",
    "## Capitulo 1: Limpieza de datos\n",
    "\n",
    "### Clase 1: Obtención , organización y manejo de datos usando la librería Pandas de Python\n",
    "\n",
    "En esta clase veremos como obtener datos y cierto manejo básico en la librería Pandas de Python de modo de poder inferir que tipo de datos estamos trabajando, usando más de un caso de estudio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset clásicos\n",
    "\n",
    "En el ámbito de la *ciencia de datos*, es usual hablar de *datsets clásicos*. Estos datasets generalmente vienen incluídos en paquetes y han servido como ejemplos prácticos a la hora de aprender métodos en esta disciplina, a lo largo de varias generaciones de estudiantes. Nosotros no seremos la excepción y nos servirán para explorar los datos y aprender a usar los comandos básicos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets no clásicos\n",
    "\n",
    "Por otra parte, no siempre tendremos a nuestra disposición datasets clásicos. Es más, en las aplicaciones de verdad, ya sea en la academia o en la industria, tendremos que acostumbrarnos a usar datasets \"sucios\", o que provienen de fuentes extrañas, o que no estén en un formato deseado. El primer paso de un *data scientist* es lidiar con ese tipo de datasets y es bueno que empecemos a acostumbrarnos a trabajar con ellos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando un csv (comma separated values) desde una carpeta específica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/aleph/Dropbox/Docencia posgrado/Analisis de Datos  MDS19/datasets')\n",
    "\n",
    "\"\"\"\n",
    "Dentro del paréntesis deben poner la URL de la carpeta donde guardaron el archivo IRIS.csv\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando la libreria pandas\n",
    "import pandas as pd # despues del \"as\" puedes poner LO QUE QUIERAS, pero por convención, se usa pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('IRIS.csv')\n",
    "\n",
    "#generalmente se usa df, y de nuevo, tu le puedes poner el nombre que quieras ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viendo el encabezado de la data para ver como es\n",
    "\n",
    "data.head() #dentro del parentesis puedes poner el numero entero que quieras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿que tipos de datos tiene nuestro dataframe?\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿como se mueven las variables continuas?\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿y qué pasa con la columna \"species\"?\n",
    "\n",
    "#veamos las categorías que contiene:\n",
    "data.species.unique()\n",
    "\n",
    "# el método unique sirve para  mostrar las posibilidades únicas de cada columna. Su equivalente en R es unique(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observación: Python es un lenguaje muy intuitivo y es posible usar los \"métodos\" para denominar a las columnas. Pero para que esto sea posible, el string o label de la columna debe ser una \"unidad\" completa o monomio. Si tiene un nombre que exceda el \"monomio\", se recomienda usar el guión bajo para generar el monomio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suponga que un investigador a cargo del área donde usted trabaja le dice que sólo nos interesa analizar la especie iris versicolor, ya que esa especie tiene recomendaciones para problemas hepáticos.\n",
    "\n",
    "Vamos a crear un dataframe donde solo esté esa especie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En pandas, para filtrar se debe usar el comando lógico \"==\" \n",
    "\n",
    "df_aux=data[data.species=='Iris-virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describiendo los datos\n",
    "\n",
    "df_aux.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio: inferencias sobre los datos:\n",
    "\n",
    "- Si un colega que está trabajando con los mismos datos, le dice que vio en el dataset una Iris-virginica con pétalo de largo 4.845 . ¿Usted le creería?\n",
    "- Si alguien dice que ha visto Iris-virginica con pétalos de largo 7, ¿qué le diría?\n",
    "\n",
    "\n",
    "#### Para indagar:\n",
    "\n",
    "- Lea la documentación correspondiente a los métodos **describe** y **unique** de la librería pandas y aplique algo distinto al paréntesis vacío. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando un csv desde una url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### importando desde una URL\n",
    "\n",
    "data2=pd.read_csv('https://bit.ly/2ZNXHTQ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cada columna representa una serie\n",
    "type(data2.año)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece ser que tenemos un datset que es una serie de tiempo, en donde las columnas que tienen que ver con la fecha, están separadas y no se ve un orden aparente. Hay otras dos coliumnas que corresponden a cantidad y venta, es decir, estamos hablando de un dataset que proviene directamente de la industria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creando la columna de fechas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que hay que hacer, es crear una columuna uniendo lo que se ve en la columna de año, en la columna de mes y en la columna de día. ¿Cómo lo hacemos? Hay más de una manera. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método 1: Concatenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esto lanzará un error\n",
    "\n",
    "data2['fecha']=data2.dia+ '-' + data2.mes+'-'+data2.año"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A tener en cuenta** : Tener errores no nos hace menos data scientists ni nada por el estilo. No existe ser humano que no haya tenido errores en programación. Los errores sirven para aprender, es la gracia de la investigación y la ciencia en general. Quien busque la perfección debe replantearse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Donde está el error?* En que se quiere concatenar datos que no son string (excepto por el guión \"-\")\n",
    "\n",
    "**La solución es usar el método map, cambiando el tipo de dato a string**. Esto es porque cada columna es una Serie (Series) y map actúa sobre cada elemento de una serie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['fecha']=data2.dia.map(str) + '-' + data2.mes.map(str) + '-' + data2.año.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['fecha']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea entonces es ordenar los datos por fecha. Veamos que pasa si ordeno solo la columna de fechas recién creada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.sort_values(by=['fecha']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿qué pasó? ¿es correcto el orden?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Debemos transformar el string a fecha usando pd.to_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['fecha']=pd.to_datetime(data2['fecha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.sort_values(by=['fecha'], inplace=True) # se puede usar con inplace=True para no tener que hacer x=x(condicion nueva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sólo nos interesa la fecha, la venta y la cantidad, por lo tanto, seleccionamos las columans de interés:\n",
    "\n",
    "data2=data2[['fecha','cantidad','venta']]\n",
    "data2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Por último, observamos que los indices del nuevo dataframe están desordenados. \n",
    "Para el análisis de datos, en ocasiones es MUY IMPORTANTE que los índices estén ordenados\n",
    "Para eso usamos el método reset_index. Debemos usar drop si no queremos que el índice antiguo \n",
    "se transforme en una columna nueva\n",
    "\"\"\"\"\"\n",
    "data2.reset_index(inplace=True, drop=True)\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método 2: Usando el método  apply, format y el cálculo lambda "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El método **apply** sirve para aplicar una función a toda una columna o toda una fila en un determinado dataframe en pandas.\n",
    "- El formateo (format) hace que cada expresion vacía se llene con lo que está dentro del parentesis '{}'. Por lo tanto es una manera *simple* de pasar a string.   \n",
    "- EL **cálculo lambda** proviene de la lógica matemática para definir el concepto de función y abordar el problema de la recursividad. En python se usa para definir funciones de una manera simple y directa usando la siguiente lógica:\n",
    "\n",
    "<h3><center>lambda variable: expresion(variable)</center></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, este método, que es más sotisificado que el anterior, consiste en aplicar a toda la columna un formateo de string usando una función definida por el cálculo lambda. Luego pasamos a formato de fecha y reseteamos el índice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3=pd.read_csv('https://bit.ly/2ZNXHTQ')\n",
    "\n",
    "#en una sola línea:\n",
    "data3['fecha']=data3[['dia','mes','año']].apply(lambda x : '{}-{}-{}'.format(x[0],x[1],x[2]), axis=1)\n",
    "\n",
    "###\n",
    "\n",
    "data3['fecha']=pd.to_datetime(data3['fecha'])\n",
    "data3=data3[['fecha','cantidad','venta']]\n",
    "data3.sort_values('fecha', inplace=True)\n",
    "data3.reset_index(inplace=True, drop=True)\n",
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "- Calcular una columna de precio\n",
    "- El cliente necesita las salidas en el formato YY-MM-DD. Cree otro dataset con las fechas en ese formato usando cualquier de los dos métodos (de preferencia el 2)\n",
    "- Suponga que un data scientist senior de su empresa le pide analizar **un año de datos** con fecha máxima el mes julio 2019, ya que se debe evaluar las ventas del ultimo año y en producción aun no se cierra el mes de agosto 2019. Cree un dataframe auxiliar con esta consideración.\n",
    "- ¿Por qué hay cree usted que hay dos datos por cada fecha?\n",
    "\n",
    "**Tarea**\n",
    "\n",
    "- Cree un nuevo dataset en donde cada fecha debe aparecer una sola vez.\n",
    "- Calcule el precio promedio del último año cerrado\n",
    "- ¿En cuántos días las transacciones estuvieron por sobre los 650 pesos? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

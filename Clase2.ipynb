{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis y limpieza de datos\n",
    "\n",
    "**Profesor responsable**: Jorge Alexis Castillo Sepúlveda, PhD, MSc & Math. Eng.\n",
    "\n",
    "## Capítulo 1: Limpieza de datos (cont.)\n",
    "\n",
    "## Clase 2, parte a: Profundizando en la librería *Pandas* \n",
    "\n",
    "En esta sección de clase, profundizaremos en la librería Pandas de Python. El objetivo es conocer los métodos más útiles de esta librería y como ésta nos puede ayudar a organizar bien la información contenida en los datos.\n",
    "\n",
    "*Disclaimer*: Ciertamente, es imposible cubrir la totalidad de los contenidos de la librería en una clase lectiva. Es deber del alumno profundizar en ello. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajaremos con el siguiente dataset: https://www.kaggle.com/rpparada/rendimiento-escolar-chile . La documentación de las columnas y tipos de variables se encuentra en este enlace: http://datos.mineduc.cl/datasets/171552-er-resumen-rendimiento-por-ue.download/\n",
    "\n",
    "Esta es una base de datos bastante grande y tediosa para propósitos académicos, por ello, seleccionaremos el archivo correspondiente al año 2017 y las siguientes columnas:\n",
    "\n",
    "- AGNO (año de la información)\n",
    "- NOM_RBD: nombre del establecimientp\n",
    "- COD_REG_RBD: Código de región en que se ubica el establecimiento (ver anexo)\n",
    "- COD_PRO_RBD: Código oficial de provincia en que se ubica el establecimiento (ver anexo)\n",
    "- NOM_COM_RBD: Nombre de la comuna\n",
    "- COD_DEPE: Código de dependencia del establecimiento (1: municipal/2:part. subvencionado/3: part. pagado/4: corporacion administracion delegada)\n",
    "- RURAL_RBD: Área geográfica en que se ubica el establecimiento (0: irbano/1:rural)\n",
    "- ESTADO_ESTAB: Estado del establecimiento (1: funcionando)\n",
    "- REP_HOM_TO (Número total de hombres reprobados, en el tipo de enseñanza)\n",
    "- REP_MUJ_TO (Número total de mujeres reprobadas, en el tipo de enseñanza)\n",
    "- PROM_ASIS_APR_HOM: Porcentaje promedio de Asistencia de los alumnos hombres aprobados de un mismo nivel de Enseñanza\n",
    "- PROM_ASIS_APR_MUJ: Porcentaje promedio de Asistencia de las alumnas mujeres aprobadas de un mismo nivel de Enseñanza\n",
    "- PROM_ASIS_APR_SI: Porcentaje promedio de Asistencia de los alumnos sin información de género aprobados de un mismo nivel de Enseñanza\n",
    "- PROM_ASIS_APR: Porcentaje promedio de Asistencia de los alumnos aprobados de un mismo nivel de Enseñanza\n",
    "- PROM_ASIS_REP_HOM: Porcentaje promedio de Asistencia de los alumnos hombres reprobados de un mismo nivel de Enseñanza\n",
    "- PROM_ASIS_REP_MUJ: Porcentaje promedio de Asistencia de las alumnas mujeres reprobadas de un mismo nivel de Enseñanza\n",
    "- PROM_ASIS_REP: Porcentaje promedio de Asistencia de los alumnos reprobados de un mismo nivel de Enseñanza\n",
    "- PROM_ASIS: Porcentaje promedio de Asistencia de los alumnos de un mismo nivel de Enseñanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leyendo los datos y seleccionando las columnas indicadas:\n",
    "\n",
    "import os\n",
    "\n",
    "#usted debe cambiar este path\n",
    "path='C:/Users/aleph/Dropbox/Docencia posgrado/Analisis de Datos  MDS19/datasets/datos_escolares'\n",
    "os.chdir(path)\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.read_csv('20180214_Resumen_Rendimiento 2017_20180131.csv', sep=';',\n",
    "               usecols=['AGNO','NOM_RBD','COD_REG_RBD','COD_PRO_RBD','NOM_COM_RBD','COD_DEPE','RURAL_RBD',\n",
    "                       'ESTADO_ESTAB', 'REP_HOM_TO','REP_MUJ_TO','PROM_ASIS_APR_HOM','PROM_ASIS_APR_MUJ',\n",
    "                       'PROM_ASIS_APR_SI','PROM_ASIS_APR','PROM_ASIS_REP_HOM','PROM_ASIS_REP_MUJ',\n",
    "                       'PROM_ASIS_REP','PROM_ASIS'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿encuentra algo raro en el *display* de los datos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos formatear bien nuestros datos. Los decimales deben ir en punto. Para ello, se puede usar la opción **decimal=','** en read_csv para que reconozca la coma como un decimal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, en este caso particular, no funciona esta opción (ejercicio: inténtelo). Vamos a probar una opción más larga, que es remplazar manualmente las comas por puntos y luego reformateando. Esto es parte de la limpieza de datos que todo *data scientist* debe enfrentar más de una vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PROM_ASIS_APR_HOM'] = [x.replace(',', '.') for x in df['PROM_ASIS_APR_HOM']]\n",
    "df['PROM_ASIS_APR_MUJ'] = [x.replace(',', '.') for x in df['PROM_ASIS_APR_MUJ']]\n",
    "df['PROM_ASIS_APR_SI'] = [x.replace(',', '.') for x in df['PROM_ASIS_APR_SI']]\n",
    "df['PROM_ASIS_APR'] = [x.replace(',', '.') for x in df['PROM_ASIS_APR']]\n",
    "df['PROM_ASIS_REP_HOM'] = [x.replace(',', '.') for x in df['PROM_ASIS_REP_HOM']]\n",
    "df['PROM_ASIS_REP_MUJ'] = [x.replace(',', '.') for x in df['PROM_ASIS_REP_MUJ']]\n",
    "df['PROM_ASIS_REP'] = [x.replace(',', '.') for x in df['PROM_ASIS_REP']]\n",
    "df['PROM_ASIS'] = [x.replace(',', '.') for x in df['PROM_ASIS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver si funcionó, intentemos una operación numérica:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PROM_ASIS_APR_HOM']+df['PROM_ASIS_APR_HOM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No está funcionando. Podemos usar pd.to_numeric para forzar a que el string con punto decimal se convierta en un número:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(df.PROM_ASIS_APR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#que esta pasando ahi?\n",
    "df.PROM_ASIS_APR.iloc[91]\n",
    "\n",
    "#NOTA: Ya explicaré el operador iloc, es parte del contenido de etsa clase (indexación/selección)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta manera, descubrimos el problema. Debemos remplazar ese *espacio*, por *nada* y luego llevarlo a numérico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PROM_ASIS_APR_HOM'] = [x.replace(' ', '') for x in df['PROM_ASIS_APR_HOM']]\n",
    "df['PROM_ASIS_APR_MUJ'] = [x.replace(' ', '') for x in df['PROM_ASIS_APR_MUJ']]\n",
    "df['PROM_ASIS_APR_SI'] = [x.replace(' ', '') for x in df['PROM_ASIS_APR_SI']]\n",
    "df['PROM_ASIS_APR'] = [x.replace(' ', '') for x in df['PROM_ASIS_APR']]\n",
    "df['PROM_ASIS_REP_HOM'] = [x.replace(' ', '') for x in df['PROM_ASIS_REP_HOM']]\n",
    "df['PROM_ASIS_REP_MUJ'] = [x.replace(' ', '') for x in df['PROM_ASIS_REP_MUJ']]\n",
    "df['PROM_ASIS_REP'] = [x.replace(' ', '') for x in df['PROM_ASIS_REP']]\n",
    "df['PROM_ASIS'] = [x.replace(' ', '') for x in df['PROM_ASIS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapeamos a flota la coerción a numérico:\n",
    "df.PROM_ASIS_APR_HOM=pd.to_numeric(df.PROM_ASIS_APR_HOM).map(float)\n",
    "df.PROM_ASIS_APR_MUJ=pd.to_numeric(df.PROM_ASIS_APR_MUJ).map(float)\n",
    "df.PROM_ASIS_APR_SI=pd.to_numeric(df.PROM_ASIS_APR_SI).map(float)\n",
    "df.PROM_ASIS_APR=pd.to_numeric(df.PROM_ASIS_APR).map(float)\n",
    "df.PROM_ASIS_REP_HOM=pd.to_numeric(df.PROM_ASIS_REP_HOM).map(float)\n",
    "df.PROM_ASIS_REP_MUJ=pd.to_numeric(df.PROM_ASIS_REP_MUJ).map(float)\n",
    "df.PROM_ASIS_REP=pd.to_numeric(df.PROM_ASIS_REP).map(float)\n",
    "df.PROM_ASIS=pd.to_numeric(df.PROM_ASIS).map(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que estñe todo en orden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos limpiado nuestro dataset, podemos empezar a trabajar con él. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexando datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En *pandas* existen dos operadores para indexar datos: **iloc** y **loc**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iloc:** este operador se basa en la posición y usa sólo números enteros, pudiendo ser un numero entero por sí mismo, una lista o arreglo  de enteros, un *slice* (a:b) o un arreglo booleano. La sintaxis general es **df.iloc[indice fila, indice columna]** en donde el ìndice va desde 0 hasta el largo (de la fila o columna) menos 1. Si solo se pone una dimensión dentro del corchete, toma la fila. Veamos algunos ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para seleccionar  la primera fila (notar que el output es una serie)\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionar la ultima fila\n",
    "df.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionar las primeras 4 filas\n",
    "df.iloc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#el elemento de la 44ª fila y 4ª columna\n",
    "df.iloc[43,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ultima columna\n",
    "df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#primeros tres elementos de la ultima columna\n",
    "df.iloc[[0,1,2],-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 1**:  Siga intentando con otras opciones (libre).\n",
    "\n",
    "**Ejercicio 2**: En vez de usar enteros por si solos **(.iloc[i])**, use una lista , i.e. **(.iloc[[i]])** ¿En qué cambia el output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**loc:** este operador basa su selección usando las etiquetas (nombres) de los índices y de las columnas. Puede ser simple o una lista de etiquetas. También pueden ser un *slice* de etiquetas, o un arreglo booleano. Veamos ejemplos:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿como se llaman nuestros índices?\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#¿como se llaman nuestras columnas?\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs: tambien sirve usar keys()\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionamos el primer elemento de las columnas AGNO y PROM_ASIS_APR_HOM\n",
    "print(df.loc[0,'AGNO'])\n",
    "print(df.loc[0,'PROM_ASIS_APR_HOM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imponemos que el indice sea el nombre de cada establecimiento:\n",
    "df.set_index('NOM_RBD', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ESCUELA IGNACIO CARRERA PINTO'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#veamos algun colegio al azar\n",
    "df.index[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#queremos ver el procentaje promedio de asistencia de los alumnos de este colegio:\n",
    "\n",
    "df.loc['ESCUELA IGNACIO CARRERA PINTO','PROM_ASIS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿que explicación le encuentra?\n",
    "\n",
    "veamos que datos contiene ese índice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['ESCUELA IGNACIO CARRERA PINTO']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vemos que el nombre del colegio no basta, ¿qué otra columna usaría usted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trabajaremos con multi indice:\n",
    "df.set_index(['NOM_RBD','NOM_COM_RBD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hay que resetear el ìndice!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(['NOM_RBD','NOM_COM_RBD'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ESCUELA IGNACIO CARRERA PINTO', 'MARIA ELENA')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[('ESCUELA IGNACIO CARRERA PINTO', 'MARIA ELENA')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#¿Cual fue el promedio de asistencia de la escuela ignacio carrera pinto en maria elena?\n",
    "df.loc[('ESCUELA IGNACIO CARRERA PINTO', 'MARIA ELENA'),'PROM_ASIS']\n",
    "\n",
    "#pruebe poniendo .values al final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# el operador loc tambien admite operadores booleanos\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "df.loc[df.NOM_RBD=='ESCUELA IGNACIO CARRERA PINTO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y seleccionar columnas especificas de acuerdo a ello..\n",
    "df.loc[df.NOM_RBD=='ESCUELA IGNACIO CARRERA PINTO', ['NOM_COM_RBD','PROM_ASIS_APR_MUJ']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios:**\n",
    "\n",
    "1) Vaya probando libremente varias opciones , lea la documentación que se encuentra en el sitio del paquete.\n",
    "\n",
    "2) Tanto como para loc e iloc, estudie como indexar por *callables*. Esto se encuentra en la documentación también y se añadió hace poco en la actualización de Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Combinando datos\n",
    "\n",
    "Es hora de empezar a combinar distintos datos. Suponga que le dice que debe analizar además del año 2017, el año 2016. Lea ese archivo y repita todo lo que se hizo de limpieza de datos en las variables numèricas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv('20170220_Resumen_Rendimiento 2016_20170131.csv', sep=';',\n",
    "               usecols=['AGNO','NOM_RBD','COD_REG_RBD','COD_PRO_RBD','NOM_COM_RBD','COD_DEPE','RURAL_RBD',\n",
    "                       'ESTADO_ESTAB', 'REP_HOM_TO','REP_MUJ_TO','PROM_ASIS_APR_HOM','PROM_ASIS_APR_MUJ',\n",
    "                       'PROM_ASIS_APR_SI','PROM_ASIS_APR','PROM_ASIS_REP_HOM','PROM_ASIS_REP_MUJ',\n",
    "                       'PROM_ASIS_REP','PROM_ASIS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sacamos esa columan que estaba en la data, \n",
    "#lamentablemente la documentación de la página estaba mala! mas de una vez esto les puede pasar,\n",
    "#los errores humanos son inevitables...\n",
    "\n",
    "df2=pd.read_csv('20170220_Resumen_Rendimiento 2016_20170131.csv', sep=';',\n",
    "               usecols=['AGNO','NOM_RBD','COD_REG_RBD','COD_PRO_RBD','NOM_COM_RBD','COD_DEPE','RURAL_RBD',\n",
    "                       'ESTADO_ESTAB', 'REP_HOM_TO','REP_MUJ_TO','PROM_ASIS_APR_HOM','PROM_ASIS_APR_MUJ',\n",
    "                       'PROM_ASIS_APR','PROM_ASIS_REP_HOM','PROM_ASIS_REP_MUJ',\n",
    "                       'PROM_ASIS_REP','PROM_ASIS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#procedemos con la limpieza:\n",
    "df2['PROM_ASIS_APR_HOM'] = [x.replace(',', '.') for x in df2['PROM_ASIS_APR_HOM']]\n",
    "df2['PROM_ASIS_APR_MUJ'] = [x.replace(',', '.') for x in df2['PROM_ASIS_APR_MUJ']]\n",
    "#df2['PROM_ASIS_APR_SI'] = [x.replace(',', '.') for x in df2['PROM_ASIS_APR_SI']]\n",
    "df2['PROM_ASIS_APR'] = [x.replace(',', '.') for x in df2['PROM_ASIS_APR']]\n",
    "df2['PROM_ASIS_REP_HOM'] = [x.replace(',', '.') for x in df2['PROM_ASIS_REP_HOM']]\n",
    "df2['PROM_ASIS_REP_MUJ'] = [x.replace(',', '.') for x in df2['PROM_ASIS_REP_MUJ']]\n",
    "df2['PROM_ASIS_REP'] = [x.replace(',', '.') for x in df2['PROM_ASIS_REP']]\n",
    "df2['PROM_ASIS'] = [x.replace(',', '.') for x in df2['PROM_ASIS']]\n",
    "\n",
    "df2['PROM_ASIS_APR_HOM'] = [x.replace(' ', '') for x in df2['PROM_ASIS_APR_HOM']]\n",
    "df2['PROM_ASIS_APR_MUJ'] = [x.replace(' ', '') for x in df2['PROM_ASIS_APR_MUJ']]\n",
    "#df2['PROM_ASIS_APR_SI'] = [x.replace(' ', '') for x in df2['PROM_ASIS_APR_SI']]\n",
    "df2['PROM_ASIS_APR'] = [x.replace(' ', '') for x in df2['PROM_ASIS_APR']]\n",
    "df2['PROM_ASIS_REP_HOM'] = [x.replace(' ', '') for x in df2['PROM_ASIS_REP_HOM']]\n",
    "df2['PROM_ASIS_REP_MUJ'] = [x.replace(' ', '') for x in df2['PROM_ASIS_REP_MUJ']]\n",
    "df2['PROM_ASIS_REP'] = [x.replace(' ', '') for x in df2['PROM_ASIS_REP']]\n",
    "df2['PROM_ASIS'] = [x.replace(' ', '') for x in df2['PROM_ASIS']]\n",
    "\n",
    "df2.PROM_ASIS_APR_HOM=pd.to_numeric(df2.PROM_ASIS_APR_HOM).map(float)\n",
    "df2.PROM_ASIS_APR_MUJ=pd.to_numeric(df2.PROM_ASIS_APR_MUJ).map(float)\n",
    "#df2.PROM_ASIS_APR_SI=pd.to_numeric(df2.PROM_ASIS_APR_SI).map(float)\n",
    "df2.PROM_ASIS_APR=pd.to_numeric(df2.PROM_ASIS_APR).map(float)\n",
    "df2.PROM_ASIS_REP_HOM=pd.to_numeric(df2.PROM_ASIS_REP_HOM).map(float)\n",
    "df2.PROM_ASIS_REP_MUJ=pd.to_numeric(df2.PROM_ASIS_REP_MUJ).map(float)\n",
    "df2.PROM_ASIS_REP=pd.to_numeric(df2.PROM_ASIS_REP).map(float)\n",
    "df2.PROM_ASIS=pd.to_numeric(df2.PROM_ASIS).map(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le piden hacer un análisis en una sola tabla. Entonces lo que hay que hacer es juntar las tablas. Para eso usamos el método **concat**, cuya documentación se encuentra en https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siguiendo la documentación:\n",
    "\n",
    "frames=[df,df2]\n",
    "data_combinada=pd.concat(frames)\n",
    "data_combinada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encuentre una explciación al output que acaba de ver!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir: Debemos eliminar 3 columnas en df para que sean compatibles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['AGNO', 'NOM_RBD', 'COD_REG_RBD', 'COD_PRO_RBD', 'NOM_COM_RBD',\n",
    "       'COD_DEPE', 'RURAL_RBD', 'ESTADO_ESTAB', 'REP_HOM_TO', 'REP_MUJ_TO',\n",
    "       'PROM_ASIS_APR_HOM', 'PROM_ASIS_APR_MUJ', 'PROM_ASIS_APR',\n",
    "       'PROM_ASIS_REP_HOM', 'PROM_ASIS_REP_MUJ', 'PROM_ASIS_REP', 'PROM_ASIS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[df,df2]\n",
    "data_combinada=pd.concat(frames)\n",
    "data_combinada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Construya una tabla donde solo se muestre  los promedios de asistencia (ultima columna), con índice el nombre del colegio, nombre de la comuna y ubicación geográfica (rural/urbana)\n",
    "\n",
    "**Para indagar** Lea toda la documentación y estudie los demás métodos (merge, join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupando datos\n",
    "\n",
    "Agrupar datos es una tarea común en el análisis. En este apartado usaremos el método **groupby** (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponga que le preguntan: ¿Cuántos hombres repitieron entre 2016 y 2017 en escuelas rurales municipales que estén en funcionamiento? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método **groupby** puede agrupar por distintas columnas de interes, y al final se elije una operación, que puede ser sumar, contar, obteener máximo, mínimo, o una podneración arbitraria si se desea. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observe que pasa con la opcion as_index.\n",
    "\n",
    "agrupa1=data_combinada.groupby(['RURAL_RBD','ESTADO_ESTAB']).sum()\n",
    "#agrupa1=data_combinada.groupby(['RURAL_RBD','ESTADO_ESTAB'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que mirar en la columna rural_rbd el indice 1, y en el estado del establecimiento el dato 1 que indica que está en funcionamiento.\n",
    "¿Repitieron más hombres o mujeres?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le preguntan por el promedio de asistencia, de los que repitieron: ¿llegaron mas hombres o mujeres a las escuelas riurales municipales (activas)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "agrupa2=data_combinada.groupby(['RURAL_RBD','ESTADO_ESTAB'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agrupa2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponga ahora que le preguntan por la comuna que tuvo mejor asistencia promedio en el 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usaremos varias cosas que hemos visto:\n",
    "\n",
    "agrupa3=df2.groupby('NOM_COM_RBD').mean()  #agrupo por comuna\n",
    "agrupa3.sort_values(by=['PROM_ASIS'], ascending=False, inplace=True) #ordeno en orden descendiente por promedio de asistencia\n",
    "agrupa3.iloc[[0]] #muestro la primera fila, en formato dataframe (esto ultimo s epeude obviar y mostrar como lista si se desea, pero acceder al dato es mas facil en un dataframe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fue Pumanque, con un 98% de asistencia!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios:**\n",
    "\n",
    "Resuelva los siguientes problemas:\n",
    "\n",
    "- ¿Qué comuna tuvo la mayor cantidad de mujeres repitentes en colegios urbanos particulares subvencionados entre 2016 y 2017?\n",
    "- De todos colegios particulares pagados, indique el que tuvo peor desempeño entre 2016 y 2017.\n",
    "\n",
    "**Para indagar**\n",
    "\n",
    "Estudie como usar una ponderación respecto al valor de una columna específica. Pista: usar un *dicccionario* y calculo lambda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoteando tablas\n",
    "\n",
    "La opreación de pivoteo es un mapeo entre columnas y que se pasan a una matriz mostrando todos los casos posibles, por lo tanto puede mostrar resultados parecidos al groupby. Cuando se relacionan dos variables, es muy util cuando se usan métodos dependientes de matrices, como econometría, análisis de redes, etc. \n",
    "\n",
    "Veremos un ejemplo sencillo con la dtaa que hemos estado usando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tomaremos como pivote el promedio de asistencia, en donde el indice es el nombre de la comuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoteo=data_combinada.pivot_table('PROM_ASIS',index='NOM_COM_RBD')\n",
    "pivoteo.sort_values(by='PROM_ASIS', ascending =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviamente obtenemos el mismo resultado anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible ver un valor de acuerdo a un indice fijo y una columna a gusto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoteo2=data_combinada.pivot_table('PROM_ASIS',index='NOM_COM_RBD', columns='RURAL_RBD')\n",
    "pivoteo2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarea:** Estudie desde el handbook los ejemplos de pivoteo que se encuentran ahì"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajando con *missing data* \n",
    "\n",
    "¿qué son los valores faltantes? pueden ser valores vacíos (no hay registro o se perdió el dato), o pueden ser datos NaN debido a una operación no permitida (por ejemplo, una división por 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#veamos si tenemos missing data usando isnull\n",
    "\n",
    "data_combinada.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(data_combinada['PROM_ASIS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliar=pd.isnull(data_combinada['PROM_ASIS'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliar[auxiliar==True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_combinada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En ciertas ocasiones, puede ser util eliminar datos faltantes, acá un ejemplo de eliminar las filas en donde en la ultima columna hayan datos faltantes\n",
    "\n",
    "data_combinada.dropna(subset=['PROM_ASIS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase 2, parte b: \n",
    "\n",
    "## Capítulo 2: (Introducción al) análisis exploratorio de datos\n",
    "\n",
    "Ahora introduciremos algunos principios del análisis exploratorio de datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repaso de estadística descriptiva\n",
    "\n",
    "- Muestra\n",
    "- Promedio\n",
    "- Desviación estándar\n",
    "- Intervalos de confianza, pruebas de hipótesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#veamos algunos graficos típicos, importemos las librerias mas usadas:\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploración visual de datos usando estadística descriptiva\n",
    "\n",
    "- **Histogramas**\n",
    "\n",
    "- **Correlaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionaremos un caso particular\n",
    "df_=data_combinada[data_combinada.NOM_COM_RBD=='ARICA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogramas de frecuencias, veamos el promedio de asistencia:\n",
    "\n",
    "n_bins=10 #el numero de bins en q se dividirá el grafico\n",
    "plt.hist(df_['PROM_ASIS'],n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repitentes hombres en 15 bins\n",
    "plt.hist(df_['REP_HOM_TO'],15)\n",
    "\n",
    "#','REP_MUJ_TO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repitentes hombres en 15 bins\n",
    "plt.hist(df_['REP_MUJ_TO'],15)\n",
    "\n",
    "#','REP_MUJ_TO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varios\n",
    "\n",
    "df_num=df_.select_dtypes(include=['int64', 'float64']) #seleccionar variables numericas\n",
    "df_num.hist(bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlaciones\n",
    "\n",
    "for i in range(0,len(df_num.columns),5):\n",
    "    sns.pairplot(df_num,y_vars=['REP_HOM_TO'],x_vars=df_num.columns[i:i+5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=df_num.drop('REP_HOM_TO',axis=1).corr()\n",
    "sns.heatmap(corr[(corr >= 0.8) | (corr <= -0.8)],\n",
    "           cmap='viridis',vmax=1.0,vmin=-1.0,linewidths=0.1,\n",
    "           annot=True,annot_kws={\"size\":8},square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regresion entre promedio de sistencia y repitencia\n",
    "sns.regplot(df_['PROM_ASIS'],df_['REP_HOM_TO'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
